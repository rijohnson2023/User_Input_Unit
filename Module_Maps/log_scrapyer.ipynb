{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rought plan\n",
    "\n",
    "1. Set up path to place files\n",
    "2. get the source_directory to search for the files\n",
    "3. os.walk() to find the files\n",
    "4. open the file\n",
    "   1. move pointer to the end of file if not using \"a+\" mode\n",
    "   2. normal termination line\n",
    "      1. if no normal termination line break and move on to next file\n",
    "   3. move pointer to the top of the file\n",
    "   4. iterate using readline\n",
    "      1. startswith(\"%\"), grab line\n",
    "      2. startswith(\"#\") grab line and all lines after until reach \"------\" line\n",
    "   5. end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate/setup directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Riley/Documents/Research/User_Input_Module/LogFile\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def set_data_path() -> str:\n",
    "    outfile_name = input(\"Name the file to store the data:\\n(Do not include the extension)\\n\")\n",
    "\n",
    "    # Locate current working directory as destination for report\n",
    "    data_path = os.path.join(os.getcwd(),outfile_name)\n",
    "\n",
    "    while True :\n",
    "        # Two answers: acceptable: 1. path, 2. \"\", all else are bad\"\n",
    "        answer = str(input(\"The data recorded will be at path:\\n%10s\\nHit enter to proceed, or type new path without '/LogData.csv':\\n  \" % data_path))\n",
    "        if answer == \"\" :\n",
    "            break\n",
    "        elif os.path.isdir(answer) :\n",
    "            data_path = os.path.join(answer,outfile_name)\n",
    "            break\n",
    "\n",
    "    return data_path\n",
    "\n",
    "def test() :\n",
    "    \"\"\"\n",
    "    Simple data file string is:\n",
    "            LogFile\n",
    "\n",
    "    Copy and past path:\n",
    "            /Users/Riley/Documents/Research/User_Input_Module/\n",
    "    \"\"\"\n",
    "    data_path = set_data_path()\n",
    "    print(data_path)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 log files were found in the directory branch:\n",
      "/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/\n",
      "['/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChlorideClTS.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/NotNormalTerm.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/EmptyFile.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/Pd2p-ene-CO-transcis-P-fromciscis.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/Cl.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChloride.log']\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "def find_files_in_dir() -> list[str] :\n",
    "    # Get valid source directory from user\n",
    "    source_dir = input(\"Please input the directory path to search:\\n\")\n",
    "    while not os.path.isdir(source_dir) :\n",
    "        source_dir = input(\"Invalid path, enter a new directory path to search:\\n\")\n",
    "\n",
    "    # Create a list of all the log files in the directory\n",
    "    listoffiles = list()\n",
    "    for (dirpath, dir_names, filenames) in os.walk(source_dir):\n",
    "        listoffiles += [os.path.join(dirpath,file) for file in filenames if file.split(\".\")[len(file.split(\".\"))-1] == \"log\"]\n",
    "\n",
    "    print(\"%d log files were found in the directory branch:\\n%s\" % (len(listoffiles), source_dir))\n",
    "    return listoffiles\n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    Use example files in the directory at the path:\n",
    "            /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/\n",
    "    \"\"\"\n",
    "    file_list = find_files_in_dir()\n",
    "    pp.pprint(file_list)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling the file challenge\n",
    "open the file\n",
    "   1. move pointer to the end of file if not using \"a+\" mode\n",
    "   2. normal termination line\n",
    "      1. if no normal termination line break and move on to next file\n",
    "   3. move pointer to the top of the file\n",
    "   4. iterate using readline\n",
    "      1. startswith(\"%\"), grab line\n",
    "      2. startswith(\"#\") grab line and all lines after until reach \"------\" line\n",
    "   5. end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File, AllylChloride.log, terminated normally.\n",
      "File, AllylChlorideClTS.log, terminated normally.\n",
      "Normal termination not detected in NotNormalTerm.log.\n",
      "File, EmptyFile.log, is empty.\n",
      "    File:\n",
      "     /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChloride.log\n",
      "     Normal termination: True\n",
      "    File:\n",
      "     /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChlorideClTS.log\n",
      "     Normal termination: True\n",
      "    File:\n",
      "     /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/NotNormalTerm.log\n",
      "     Normal termination: False\n",
      "    File:\n",
      "     /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/EmptyFile.log\n",
      "     Normal termination: False\n"
     ]
    }
   ],
   "source": [
    "from asyncore import file_wrapper\n",
    "\n",
    "def check_log_file(file_path: str, file_obj: file_wrapper) -> bool:\n",
    "    \"\"\"\n",
    "    Check log file searches the file object for the line\n",
    "    \"Normal termination of Gaussian 16\"\n",
    "\n",
    "    This is usually a substring of the last line in the log file, if it terminates correctly.\n",
    "    Sometimes with multistep calculations, there will be a \"Normal termination of Gaussian 16\"\n",
    "    line for every calculation step, or some may contain a \"Error termination of Gaussian 16.\"\n",
    "\n",
    "    We only want to record the keywords from the files that have terminated normally.\n",
    "    Those keywords are deemed as valid by the Gaussian 16 software.\n",
    "    Therefore, the log file must pass this check if we are going to count its keywords.\n",
    "\n",
    "    This function iterates over the bytes/characters of the file in reverse order until it finds the line\n",
    "    \"Normal termination of Gaussian 16.\" Keep in mind that if the file contains multi-step calculations,\n",
    "    and one of those calculations finished successfully, then the keywords will be counted.\n",
    "    \"\"\"\n",
    "    check = True\n",
    "    empty = False\n",
    "\n",
    "    file_name = (file_path.split(\"/\"))[len(file_path.split(\"/\"))-1]\n",
    "\n",
    "    # Check if size of file is 0\n",
    "    if os.stat(file_path).st_size == 0 :\n",
    "        empty = True\n",
    "        check = False\n",
    "\n",
    "    if empty != True :\n",
    "        # Move the cursor to the end of the file\n",
    "        file_obj.seek(0, os.SEEK_END)\n",
    "\n",
    "        # Get the current position of the pointer\n",
    "        pointer_location = file_obj.tell()\n",
    "        \n",
    "        # Create a buffer to keep the last read line\n",
    "        buffer = bytearray()\n",
    "\n",
    "        #Loop in reverse order until \"Normal termination\" line is found\n",
    "        while pointer_location >= 0 :\n",
    "            # Move the file pointer to the location pointed by the pointer\n",
    "            file_obj.seek(pointer_location)\n",
    "\n",
    "            pointer_location -= 1 # Shift pointer location back by 1\n",
    "            \n",
    "            new_byte = file_obj.read(1) # Read that byte/character\n",
    "\n",
    "            if new_byte == b'\\n' : # If the byte is a newline character, then the end of a line has been reached\n",
    "                line = buffer.decode()[::-1] #Fetch the line from buffer\n",
    "                if 'Normal termination of Gaussian 16' in line :\n",
    "                    print(\"File, %s, terminated normally.\" % file_name)\n",
    "                    break\n",
    "                # Reinitialize the byte array to save next line\n",
    "                buffer = bytearray()\n",
    "            else:\n",
    "                buffer.extend(new_byte)\n",
    "\n",
    "        # As file is read completely, if the line has not been detected then the file did not terminate normally.\n",
    "        if pointer_location <= 0:\n",
    "            print(\"Normal termination not detected in %s.\" %file_name)\n",
    "            check = False\n",
    "    else:\n",
    "        print(\"File, %s, is empty.\" % file_name)\n",
    "\n",
    "    return check\n",
    "\n",
    "def test():\n",
    "\n",
    "    # file_path1 is a perfectly completed calculation file\n",
    "    file_path1 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChloride.log'\n",
    "    file_path2 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChlorideClTS.log'\n",
    "\n",
    "    # file_path2 is a multi-step calculation log file. Both calculations terminated with error\n",
    "    file_path3 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/NotNormalTerm.log'\n",
    "    # file_path3 is an empty file with a log extension\n",
    "    file_path4 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/EmptyFile.log'\n",
    "    file_list = [file_path1,file_path2,file_path3, file_path4]\n",
    "    \n",
    "    checks = list()\n",
    "    for file_path in file_list :\n",
    "        with open(file_path,\"rb\") as file_obj :\n",
    "            checks.append(check_log_file(file_path,file_obj))\n",
    "    \n",
    "    [print(\"    File:\\n     %s\\n     Normal termination: %s\" %(file,checks[index])) for index, file in enumerate(file_list)]\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the data from the log file\n",
    "\n",
    "> The file has already been read as a binary file\n",
    "> \n",
    ">   - This was to check the last lines to see if it contained \"Normal termination of Gaussian 16\"\n",
    "> \n",
    ">   - There really isn't a need to read binary, unless that is required for reading the last line.\n",
    "> \n",
    "> For extracting the keywords, intuitively, it could also be read character by character. The difficulty would be making sure the characters don't get combined all together\n",
    "> \n",
    "> It seems easier to read by line. \n",
    "> \n",
    ">   - The challenge of reading line by line is if the Route section spills over into two lines, then its possible one of the keywords will get messed up. \n",
    "> \n",
    ">   - This multiplies one keyword messed up for every line spilled over. So for every line spilled over there are two bad inputs. \n",
    "> \n",
    ">   - Ideally, there won't be that many, so these will be relatively low scoring keywords when counting them as popular data.\n",
    "> \n",
    "> The next task is to compile all of the keywords into a dictionary that counts them. Then to sort the dictionary by the values, and write it into an outfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File, AllylChloride.log, terminated normally.\n",
      "['%chk=AllylChloride.chk', '%nprocs=60', '%mem=60GB']\n",
      "['opt=(maxcycles=85)', 'freq=noraman', 'hf/3-21g', 'scrf=(smd,solvent=dmso)', 'geo', 'm=connectivity', 'geom=connectivity']\n",
      "\n",
      "File, AllylChlorideClTS.log, terminated normally.\n",
      "['%oldchk=AllylChlorideClTS.chk', '%chk=AllylChlorideClTS-TS.chk']\n",
      "['opt=(ts,noeigen,readfc,modredundant)', 'freq', 'hf/3-21g', 'scrf=(smd,solvent', '=dmso)', 'nosymm', 'geom=checkpoint', 'guess=read', 'scrf=(smd,solvent=dmso)']\n",
      "\n",
      "Normal termination not detected in NotNormalTerm.log.\n",
      "File, EmptyFile.log, is empty.\n"
     ]
    }
   ],
   "source": [
    "from asyncore import file_wrapper\n",
    "\n",
    "def extract_data(file_obj: file_wrapper) -> tuple[list[str]]:\n",
    "    # Initialize local var\n",
    "    link0 = bytearray()\n",
    "    route_cmds = bytearray()\n",
    "    extracted = False\n",
    "\n",
    "    # Move the cursor to the beginning of the file\n",
    "    file_obj.seek(0)\n",
    "\n",
    "    # Read first line\n",
    "    line = file_obj.readline()\n",
    "    while line:\n",
    "        # if the line starts with a %, it is a link0 command\n",
    "        if b\"%\" in line[:3] :\n",
    "                #print(\"Found link0 input\\n%s\" % line)\n",
    "                line = line.split()\n",
    "                [link0.extend(b\" \" + elem) for elem in line if b\"%\" in elem and elem != b\"\"]\n",
    "        # if the line starts with a #, it's the route section line\n",
    "        elif b\"#\" in line[:3] :\n",
    "            #print(\"Found Route Line\\n%s\" % line)\n",
    "            line = line.split()\n",
    "            [route_cmds.extend(b\" \" + elem) for elem in line if b\"#\" not in elem and elem != b\"\"]\n",
    "            # Grab the last keyword in case line spills over\n",
    "            end_keyword = line[len(line) - 1]\n",
    "            # grab next line if the contents spill over\n",
    "            line = file_obj.readline()\n",
    "            while b'----------------------------------------------------------------------' not in line :\n",
    "                line = line.split()\n",
    "                # Chances are if the line spills it wrecks a keyword. This takes the last keyword\n",
    "                # and combines it with the first of the next line\n",
    "                start_keyword = line[0]\n",
    "                # Extend bytearray by the additional keywords\n",
    "                [route_cmds.extend(b\" \" + elem) for elem in line if elem != b\"\"]\n",
    "                # Add the joined keyword\n",
    "                route_cmds.extend(b\" \"+end_keyword+start_keyword)\n",
    "                # Read the next line\n",
    "                line = file_obj.readline()\n",
    "            extracted = True\n",
    "        \n",
    "        # Once the route section commands are collected, stop iterating over the lines in the file.\n",
    "        if extracted == True:\n",
    "            break\n",
    "        # Iterate over the next line until the route section is collected\n",
    "        line = file_obj.readline()\n",
    "\n",
    "    return link0.decode(\"ascii\").split(), route_cmds.decode(\"ascii\").split()\n",
    "\n",
    "\n",
    "def test():\n",
    "    # file_path1 is a perfectly completed calculation file\n",
    "    file_path1 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChloride.log'\n",
    "    file_path2 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChlorideClTS.log'\n",
    "\n",
    "    # file_path2 is a multi-step calculation log file. Both calculations terminated with error\n",
    "    file_path3 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/NotNormalTerm.log'\n",
    "    # file_path3 is an empty file with a log extension\n",
    "    file_path4 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/EmptyFile.log'\n",
    "    file_list = [file_path1,file_path2,file_path3, file_path4]\n",
    "\n",
    "    for file_path in file_list :\n",
    "        with open(file_path,\"rb\") as infile :\n",
    "            check = check_log_file(file_path=file_path,file_obj=infile)\n",
    "            if check : \n",
    "                (link0, route_cmds) = extract_data(file_obj=infile)\n",
    "                print(link0)\n",
    "                print(route_cmds)\n",
    "                print()\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'%chk=AllylChloride.chk': 1,\n",
      " '%chk=AllylChlorideClTS-TS.chk': 1,\n",
      " '%mem=60GB': 1,\n",
      " '%nprocs=60': 1,\n",
      " '%oldchk=AllylChlorideClTS.chk': 1}\n",
      "{}\n",
      "{'=dmso)': 1,\n",
      " 'freq': 1,\n",
      " 'freq=noraman': 1,\n",
      " 'geo': 1,\n",
      " 'geom=checkpoint': 1,\n",
      " 'geom=connectivity': 1,\n",
      " 'guess=read': 1,\n",
      " 'hf/3-21g': 1,\n",
      " 'm=connectivity': 1,\n",
      " 'nosymm': 1,\n",
      " 'opt=(maxcycles=85)': 1,\n",
      " 'opt=(ts,noeigen,readfc,modredundant)': 1,\n",
      " 'scrf=(smd,solvent': 1,\n",
      " 'scrf=(smd,solvent=dmso)': 1}\n"
     ]
    }
   ],
   "source": [
    "def update_mostFreq_data(mostFreq_dict:dict[str:int], keywords:list[str]) -> None:\n",
    "    \"\"\" \n",
    "    This function updates the mostFreq data used to track the most popular G16 keywords:\n",
    "    Update the count if the keyword is in the dictionary.\n",
    "    If the keyword is not in the dictionary, its added with a default count of 1.\n",
    "    \"\"\"\n",
    "    [mostFreq_dict.update({elem:mostFreq_dict[elem]+1}) for elem in keywords if elem in mostFreq_dict.keys()]\n",
    "    [mostFreq_dict.setdefault(elem,1) for elem in keywords if elem not in mostFreq_dict.keys()]\n",
    "\n",
    "def test():\n",
    "    # Data output by the extract data function\n",
    "    link0 = ['%chk=AllylChloride.chk', '%nprocs=60', '%mem=60GB'] + ['%oldchk=AllylChlorideClTS.chk', '%chk=AllylChlorideClTS-TS.chk']\n",
    "    route_cmds = ['opt=(maxcycles=85)', 'freq=noraman', 'hf/3-21g', 'scrf=(smd,solvent=dmso)', 'geo', 'm=connectivity', 'geom=connectivity'] + ['opt=(ts,noeigen,readfc,modredundant)', 'freq', 'hf/3-21g', 'scrf=(smd,solvent', '=dmso)', 'nosymm', 'geom=checkpoint', 'guess=read', 'scrf=(smd,solvent=dmso)']\n",
    "\n",
    "    # Initializing variables for the data. These need to be either global variables or class variables, \n",
    "    # so all the files update the same dictionary\n",
    "    link0_mostFreq = dict()\n",
    "    route_mostFreq = dict()\n",
    "\n",
    "    # Example link0 keyword update\n",
    "    pp.pprint(link0_mostFreq)\n",
    "    update_mostFreq_data(link0_mostFreq,link0)\n",
    "    pp.pprint(link0_mostFreq)\n",
    "    \n",
    "    # Example Route Section Keyword Update\n",
    "    pp.pprint(route_mostFreq)\n",
    "    update_mostFreq_data(route_mostFreq,route_cmds)\n",
    "    pp.pprint(route_mostFreq)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopping place:\n",
    "\n",
    "1. I can find all the files\n",
    "2. I can check which ones terminated normally\n",
    "3. I can extract the right data\n",
    "4. I can store that data in dictionaries where the key is the keyword and the integer is the times it shows up\n",
    "\n",
    "# To Do\n",
    "1. Sort the data\n",
    "2. Store it in a json file\n",
    "3. Store it in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'=dmso)': 1,\n",
      " 'freq': 5,\n",
      " 'freq=noraman': 4,\n",
      " 'geo': 1,\n",
      " 'geom=checkpoint': 2,\n",
      " 'geom=connectivity': 1,\n",
      " 'guess=read': 6,\n",
      " 'hf/3-21g': 7,\n",
      " 'm=connectivity': 1,\n",
      " 'nosymm': 8,\n",
      " 'opt=(maxcycles=85)': 20,\n",
      " 'opt=(ts,noeigen,readfc,modredundant)': 2,\n",
      " 'scrf=(smd,solvent': 1,\n",
      " 'scrf=(smd,solvent=dmso)': 15}\n",
      "\n",
      "[('opt=(maxcycles=85)', 20),\n",
      " ('scrf=(smd,solvent=dmso)', 15),\n",
      " ('nosymm', 8),\n",
      " ('hf/3-21g', 7),\n",
      " ('guess=read', 6),\n",
      " ('freq', 5),\n",
      " ('freq=noraman', 4),\n",
      " ('geom=checkpoint', 2),\n",
      " ('opt=(ts,noeigen,readfc,modredundant)', 2),\n",
      " ('=dmso)', 1),\n",
      " ('geo', 1),\n",
      " ('geom=connectivity', 1),\n",
      " ('m=connectivity', 1),\n",
      " ('scrf=(smd,solvent', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Sort the data by the integer value from greatest to least\n",
    "def order_dict(mostFreq_dict:dict[str:int]) -> tuple[str,int]:\n",
    "    return sorted(mostFreq_dict.items(),key=lambda elem: elem[1],reverse=True)\n",
    "\n",
    "def sorted_dict(mostFreq_dict:dict[str:int]) -> dict[str:int]:\n",
    "    return dict(sorted(mostFreq_dict.items(),key=lambda elem: elem[1],reverse=True))\n",
    "\n",
    "def test():\n",
    "    route_mostFreq =    {'=dmso)': 1,\n",
    "                        'freq': 5,\n",
    "                        'freq=noraman': 4,\n",
    "                        'geo': 1,\n",
    "                        'geom=checkpoint': 2,\n",
    "                        'geom=connectivity': 1,\n",
    "                        'guess=read': 6,\n",
    "                        'hf/3-21g': 7,\n",
    "                        'm=connectivity': 1,\n",
    "                        'nosymm': 8,\n",
    "                        'opt=(maxcycles=85)': 20,\n",
    "                        'opt=(ts,noeigen,readfc,modredundant)': 2,\n",
    "                        'scrf=(smd,solvent': 1,\n",
    "                        'scrf=(smd,solvent=dmso)': 15}\n",
    "    route_mostFreq = sorted_dict(route_mostFreq)\n",
    "    pp.pprint(route_mostFreq)\n",
    "    print()\n",
    "    route_mostFreq = order_dict(route_mostFreq)\n",
    "    pp.pprint(route_mostFreq)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'%chk=AllylChloride.chk': 1,\n",
      " '%chk=AllylChlorideClTS-TS.chk': 1,\n",
      " '%mem=60GB': 15,\n",
      " '%nprocs=60': 15,\n",
      " '%oldchk=AllylChlorideClTS.chk': 1}\n",
      "{'=dmso)': 1,\n",
      " 'freq': 5,\n",
      " 'freq=noraman': 4,\n",
      " 'geo': 1,\n",
      " 'geom=checkpoint': 2,\n",
      " 'geom=connectivity': 1,\n",
      " 'guess=read': 6,\n",
      " 'hf/3-21g': 7,\n",
      " 'm=connectivity': 1,\n",
      " 'nosymm': 8,\n",
      " 'opt=(maxcycles=85)': 20,\n",
      " 'opt=(ts,noeigen,readfc,modredundant)': 2,\n",
      " 'scrf=(smd,solvent': 1,\n",
      " 'scrf=(smd,solvent=dmso)': 15}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def export_data_json(data_path: str, link0_mostFreq: dict[str:int]=None,route_mostFreq: dict[str:int]=None) -> str :\n",
    "    # Add the json extension to data_path\n",
    "    data_path += \".json\"\n",
    "    # Organize the data into a list of dicts\n",
    "    data = [link0_mostFreq,route_mostFreq]\n",
    "    # Write the list of dicts to the json file\n",
    "    with open(data_path,\"w\") as file_obj :\n",
    "        json.dump(data,file_obj)\n",
    "    return data_path\n",
    "\n",
    "def test() :\n",
    "    data_path = '/Users/Riley/Documents/Research/User_Input_Module/LogFile'\n",
    "\n",
    "    link0_mostFreq =    {'%nprocs=60': 15,\n",
    "                        '%mem=60GB': 15,\n",
    "                        '%chk=AllylChloride.chk': 1,\n",
    "                        '%chk=AllylChlorideClTS-TS.chk': 1,\n",
    "                        '%oldchk=AllylChlorideClTS.chk': 1}\n",
    "\n",
    "    route_mostFreq =    {'opt=(maxcycles=85)': 20,\n",
    "                        'scrf=(smd,solvent=dmso)': 15,\n",
    "                        'nosymm': 8,\n",
    "                        'hf/3-21g': 7,\n",
    "                        'guess=read': 6,\n",
    "                        'freq': 5,\n",
    "                        'freq=noraman': 4,\n",
    "                        'geom=checkpoint': 2,\n",
    "                        'opt=(ts,noeigen,readfc,modredundant)': 2,\n",
    "                        '=dmso)': 1,\n",
    "                        'geo': 1,\n",
    "                        'geom=connectivity': 1,\n",
    "                        'm=connectivity': 1,\n",
    "                        'scrf=(smd,solvent': 1}\n",
    "\n",
    "    data_path = export_data_json(data_path,link0_mostFreq,route_mostFreq)\n",
    "\n",
    "    # Wiping the variables\n",
    "    link0_mostFreq = None\n",
    "    route_mostFreq = None\n",
    "\n",
    "    # Example of importing the data from the json file\n",
    "    with open(data_path,\"r\") as file_obj :\n",
    "        [link0_mostFreq,route_mostFreq] = json.load(file_obj)\n",
    "\n",
    "    pp.pprint(link0_mostFreq)\n",
    "    pp.pprint(route_mostFreq)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def export_data_csv(data_path: str, link0_mostFreq: tuple[str,int]=None,route_mostFreq: tuple[str,int]=None) -> str :\n",
    "    # Add the json extension to data_path\n",
    "    data_path += \".csv\"\n",
    "    link0_mostFreq = dict()\n",
    "    # Organize the data into a list of dicts\n",
    "    data = [(key,item) for key,item in link0_mostFreq.items()]\n",
    "    # Write the list of dicts to the json file\n",
    "    with open(data_path,\"w\") as file_obj :\n",
    "        json.dump(data,file_obj)\n",
    "    return data_path\n",
    "\n",
    "def test() :\n",
    "    data_path = '/Users/Riley/Documents/Research/User_Input_Module/LogFile'\n",
    "\n",
    "    link0_mostFreq =    {'%nprocs=60': 15,\n",
    "                        '%mem=60GB': 15,\n",
    "                        '%chk=AllylChloride.chk': 1,\n",
    "                        '%chk=AllylChlorideClTS-TS.chk': 1,\n",
    "                        '%oldchk=AllylChlorideClTS.chk': 1}\n",
    "\n",
    "    route_mostFreq =    {'opt=(maxcycles=85)': 20,\n",
    "                        'scrf=(smd,solvent=dmso)': 15,\n",
    "                        'nosymm': 8,\n",
    "                        'hf/3-21g': 7,\n",
    "                        'guess=read': 6,\n",
    "                        'freq': 5,\n",
    "                        'freq=noraman': 4,\n",
    "                        'geom=checkpoint': 2,\n",
    "                        'opt=(ts,noeigen,readfc,modredundant)': 2,\n",
    "                        '=dmso)': 1,\n",
    "                        'geo': 1,\n",
    "                        'geom=connectivity': 1,\n",
    "                        'm=connectivity': 1,\n",
    "                        'scrf=(smd,solvent': 1}\n",
    "\n",
    "    data_path = export_data_json(data_path,link0_mostFreq,route_mostFreq)\n",
    "\n",
    "    # Wiping the variables\n",
    "    link0_mostFreq = None\n",
    "    route_mostFreq = None\n",
    "\n",
    "    # Example of importing the data from the json file\n",
    "    with open(data_path,\"r\") as file_obj :\n",
    "        [link0_mostFreq,route_mostFreq] = json.load(file_obj)\n",
    "\n",
    "    pp.pprint(link0_mostFreq)\n",
    "    pp.pprint(route_mostFreq)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing all the units together\n",
    "\n",
    "1. set_data_path()\n",
    "2. find_files_in_dir()\n",
    "3. for file_path in file_list\n",
    "   1. check_log_file()\n",
    "   2. extract_data()\n",
    "   3. update_mostFreq_data()\n",
    "4. sort_dict()\n",
    "5. export_data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'%chk=AllylChloride.chk': 1,\n",
      " '%chk=AllylChlorideClTS-TS.chk': 1,\n",
      " '%chk=Cl.chk': 1,\n",
      " '%chk=Pd2p-ene-CO-transcis-P-fromciscis.chk': 1,\n",
      " '%mem=60GB': 2,\n",
      " '%nprocs=60': 1,\n",
      " '%nprocshared=60': 1,\n",
      " '%oldchk=AllylChlorideClTS.chk': 1}\n",
      "{'!': 13,\n",
      " '\"AllylChlorideClTS-TS.chk\"': 1,\n",
      " '(Angstroms': 3,\n",
      " '(old': 1,\n",
      " '-------------------': 7,\n",
      " '--------------------------': 5,\n",
      " '----------------------------': 3,\n",
      " '---------------------------------------------------------': 1,\n",
      " '----------------------------------------------------------------------': 3,\n",
      " '-0.02114': 1,\n",
      " '-0.0911': 1,\n",
      " '-0.20907': 1,\n",
      " '-0.43507': 1,\n",
      " '-0.50853': 1,\n",
      " '-0.60716': 1,\n",
      " '-0.86027': 1,\n",
      " '-0.91926': 1,\n",
      " '-0.92627': 1,\n",
      " '-0.92758': 1,\n",
      " '-1': 2,\n",
      " '-1.1381': 1,\n",
      " '-1.18797': 1,\n",
      " '-1.63832': 1,\n",
      " '-1.67126': 1,\n",
      " '-1.67677': 1,\n",
      " '-1.97653': 1,\n",
      " '-2.45815': 1,\n",
      " '-2.54339': 1,\n",
      " '-2.84843': 1,\n",
      " '-3.16718': 1,\n",
      " '-3.30476': 1,\n",
      " '0': 1,\n",
      " '0.': 1,\n",
      " '0.00013': 1,\n",
      " '0.00014': 1,\n",
      " '0.03043': 1,\n",
      " '0.05704': 1,\n",
      " '0.1255': 1,\n",
      " '0.22138': 1,\n",
      " '0.37454': 1,\n",
      " '0.4439': 1,\n",
      " '0.46792': 1,\n",
      " '0.56017': 1,\n",
      " '0.67889': 1,\n",
      " '0.75558': 1,\n",
      " '0.78255': 1,\n",
      " '0.88448': 1,\n",
      " '0.92239': 1,\n",
      " '0.92465': 1,\n",
      " '0.93421': 1,\n",
      " '1': 5,\n",
      " '1.00975': 1,\n",
      " '1.01121': 1,\n",
      " '1.20336': 1,\n",
      " '1.21518': 1,\n",
      " '1.30476': 1,\n",
      " '1.30997': 1,\n",
      " '1.33347': 1,\n",
      " '1.45817': 1,\n",
      " '1.51991': 1,\n",
      " '1.61828': 1,\n",
      " '1.67586': 1,\n",
      " '1.70603': 1,\n",
      " '1.8666': 1,\n",
      " '1.88759': 1,\n",
      " '1.90169': 1,\n",
      " '1/10=4,30=1,38=1,57=2/1,3;': 1,\n",
      " '1/10=4,30=1/3;': 1,\n",
      " '1/5=1,10=3,11=1,18=120,26=6,29=2,38=1/1,3;': 1,\n",
      " '1/5=1,11=1,18=20,26=6/3(-5);': 1,\n",
      " '1/5=1,11=1,18=20,26=6/3(2);': 1,\n",
      " '1/6=85,18=20,19=15,26=3,38=1,57=2/1,3;': 1,\n",
      " '1/6=85,18=20,19=15,26=3/3(-5);': 1,\n",
      " '1/6=85,18=20,19=15,26=3/3(2);': 1,\n",
      " '1/6=85,18=20,19=15,26=6,38=1,57=2/1,3;': 1,\n",
      " '1/6=85,18=20,19=15,26=6/3(-5);': 1,\n",
      " '1/6=85,18=20,19=15,26=6/3(2);': 1,\n",
      " '10': 1,\n",
      " '10/13=10,15=4/2;': 1,\n",
      " '10/6=1/2;': 1,\n",
      " '11/6=3,8=1,9=11,15=111,16=1/1,2,10;': 1,\n",
      " '2': 1,\n",
      " '2.': 1,\n",
      " '2.16D+00.': 1,\n",
      " '2.19495': 1,\n",
      " '2.40652': 1,\n",
      " '2/12=2,17=6,18=5,40=1/2;': 1,\n",
      " '2/9=110,12=2,15=1,17=6,18=5,40=1/2;': 1,\n",
      " '2/9=110,12=2,15=1,40=1/2;': 1,\n",
      " '2/9=110,12=2,17=6,18=5,40=1/2;': 1,\n",
      " '2/9=110,15=1/2;': 4,\n",
      " '2/9=110/2;': 1,\n",
      " '3.20876': 1,\n",
      " '3.69D+00.': 1,\n",
      " '3/5=5,11=9,14=-2,25=1,30=1,70=32205,71=1,72=21/1,2,3;': 1,\n",
      " '3/5=5,11=9,14=-4,25=1,30=1,70=32201,71=1,72=21,116=-2/1,2,3;': 1,\n",
      " '3/5=5,11=9,25=1,30=1,70=32201,71=1,72=21/1,2,3;': 1,\n",
      " '3/5=5,11=9,25=1,30=1,70=32201,71=2,72=21,140=1/1,2,3;': 1,\n",
      " '3/5=5,11=9,25=1,30=1,70=32205,71=1,72=21/1,2,3;': 1,\n",
      " '3/5=7,11=2,16=1,17=8,25=1,30=1,70=32201,71=1,72=1,74=-5/1,2,3;': 1,\n",
      " '3/5=7,6=1,11=2,16=1,17=8,25=1,30=1,70=32205,71=1,72=1,74=-5,82=7/1,2,3;': 1,\n",
      " '4': 1,\n",
      " '4//1;': 3,\n",
      " '4/5=1/1;': 1,\n",
      " '4/5=5,16=3,69=1/1;': 3,\n",
      " '5/5=2,38=5,53=1/2;': 1,\n",
      " '5/5=2,38=5,53=21,98=1/2;': 1,\n",
      " '5/5=2,38=5,53=21/2;': 3,\n",
      " '5/5=2,38=6,53=21/2;': 1,\n",
      " '6/7=2,8=2,9=2,10=2,19=2,28=1/1;': 3,\n",
      " '6/7=2,8=2,9=2,10=2,28=1/1;': 4,\n",
      " '7//1,2,3,16;': 1,\n",
      " '7/30=1/1,2,3,16;': 3,\n",
      " '7/8=1,10=1,25=1/1,2,3,16;': 1,\n",
      " '8/6=4,10=90,11=11/1;': 1,\n",
      " '9': 1,\n",
      " '99//99;': 4,\n",
      " '99/9=1/99;': 3,\n",
      " '=': 7,\n",
      " '=dmso)': 1,\n",
      " 'A': 1,\n",
      " 'Add': 1,\n",
      " 'B': 1,\n",
      " 'Berny': 4,\n",
      " 'C': 4,\n",
      " 'C,0,-0.2475887734,0.429752874,0.0120524767': 1,\n",
      " 'C,0,-0.290289215,-0.8858065531,0.0674033537': 1,\n",
      " 'C,0,1.0118266802,1.1819325199,-0.1116872583': 1,\n",
      " 'C1': 1,\n",
      " 'Card': 4,\n",
      " 'Charge': 4,\n",
      " 'Cl': 3,\n",
      " 'Cl,0,1.0820487577,1.3327527288,-2.4496755627': 1,\n",
      " 'Cl,0,1.4317208228,1.5055986407,2.1766003935': 1,\n",
      " 'Cl5': 1,\n",
      " 'Definition': 3,\n",
      " 'Degrees)': 3,\n",
      " 'Derivative': 3,\n",
      " 'Dist=': 1,\n",
      " 'EigMax=2.50D+02': 1,\n",
      " 'EigMin=1.00D-04': 1,\n",
      " 'FncErr=1.00D-07': 1,\n",
      " 'Force': 1,\n",
      " 'GradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGrad': 5,\n",
      " 'GrdErr=1.00D-07': 1,\n",
      " 'H': 6,\n",
      " 'H,0,-1.1425132255,1.019263475,0.055285699': 1,\n",
      " 'H,0,-1.2213726388,-1.4123728725,0.1573248761': 1,\n",
      " 'H,0,0.6007632219,-1.485363254,0.0245781973': 1,\n",
      " 'H,0,1.0019467677,2.2399101113,-0.1476619449': 1,\n",
      " 'H,0,1.9398457223,0.6675720299,-0.1607851803': 1,\n",
      " 'H2': 1,\n",
      " 'Info.': 3,\n",
      " 'Initial': 3,\n",
      " 'Initialization': 4,\n",
      " 'Input': 1,\n",
      " 'ModRedundant': 1,\n",
      " 'Multiplicity': 4,\n",
      " 'Name': 3,\n",
      " 'Number': 1,\n",
      " 'O': 1,\n",
      " 'Parameters': 3,\n",
      " 'Pd': 1,\n",
      " 'Radius=3.00D-01': 1,\n",
      " 'Recover': 1,\n",
      " 'Redundant': 1,\n",
      " 'Required': 4,\n",
      " 'Structure': 1,\n",
      " 'Symbolic': 3,\n",
      " 'The': 1,\n",
      " 'Title': 4,\n",
      " 'Trust': 1,\n",
      " 'Value': 3,\n",
      " 'Z-matrix:': 3,\n",
      " 'allowed': 1,\n",
      " 'and': 5,\n",
      " 'atoms': 1,\n",
      " 'b3lyp/gen': 1,\n",
      " 'been': 1,\n",
      " 'bond': 1,\n",
      " 'checkpoint': 1,\n",
      " 'connecting': 1,\n",
      " 'connectivity': 1,\n",
      " 'constant': 1,\n",
      " 'coordinates': 1,\n",
      " 'data': 1,\n",
      " 'disk.': 1,\n",
      " 'file.': 1,\n",
      " 'file:': 1,\n",
      " 'following': 1,\n",
      " 'form).': 1,\n",
      " 'found': 1,\n",
      " 'freq': 2,\n",
      " 'freq=noraman': 2,\n",
      " 'from': 1,\n",
      " 'geo': 1,\n",
      " 'geo!': 1,\n",
      " 'geo-------------------': 1,\n",
      " 'geo--------------------------': 1,\n",
      " 'geo----------------------------': 1,\n",
      " 'geo----------------------------------------------------------------------': 1,\n",
      " 'geo1/6=85,18=20,19=15,26=6,38=1,57=2/1,3;': 1,\n",
      " 'geo1/6=85,18=20,19=15,26=6/3(-5);': 1,\n",
      " 'geo1/6=85,18=20,19=15,26=6/3(2);': 1,\n",
      " 'geo2/9=110,12=2,17=6,18=5,40=1/2;': 1,\n",
      " 'geo2/9=110/2;': 1,\n",
      " 'geo3/5=5,11=9,25=1,30=1,70=32201,71=1,72=21/1,2,3;': 1,\n",
      " 'geo3/5=5,11=9,25=1,30=1,70=32205,71=1,72=21/1,2,3;': 1,\n",
      " 'geo4//1;': 1,\n",
      " 'geo4/5=5,16=3,69=1/1;': 1,\n",
      " 'geo5/5=2,38=5,53=21/2;': 1,\n",
      " 'geo6/7=2,8=2,9=2,10=2,19=2,28=1/1;': 1,\n",
      " 'geo6/7=2,8=2,9=2,10=2,28=1/1;': 1,\n",
      " 'geo7//1,2,3,16;': 1,\n",
      " 'geo99//99;': 1,\n",
      " 'geo99/9=1/99;': 1,\n",
      " 'geoBerny': 1,\n",
      " 'geoC': 1,\n",
      " 'geoCharge': 1,\n",
      " 'geoCl': 1,\n",
      " 'geoGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGrad': 1,\n",
      " 'geoH': 1,\n",
      " 'geoInitialization': 1,\n",
      " 'geoSymbolic': 1,\n",
      " 'geoTitle': 1,\n",
      " 'geom=checkpoint': 1,\n",
      " 'geom=connectivity': 3,\n",
      " 'geom=connectivity-------------------': 1,\n",
      " 'geom=connectivity---------------------------------------------------------': 1,\n",
      " 'geom=connectivity1/10=4,30=1,38=1,57=2/1,3;': 1,\n",
      " 'geom=connectivity1/10=4,30=1/3;': 1,\n",
      " 'geom=connectivity10/13=10,15=4/2;': 1,\n",
      " 'geom=connectivity10/6=1/2;': 1,\n",
      " 'geom=connectivity11/6=3,8=1,9=11,15=111,16=1/1,2,10;': 1,\n",
      " 'geom=connectivity2/12=2,17=6,18=5,40=1/2;': 1,\n",
      " 'geom=connectivity3/5=5,11=9,25=1,30=1,70=32201,71=2,72=21,140=1/1,2,3;': 1,\n",
      " 'geom=connectivity4//1;': 1,\n",
      " 'geom=connectivity5/5=2,38=5,53=21,98=1/2;': 1,\n",
      " 'geom=connectivity6/7=2,8=2,9=2,10=2,28=1/1;': 1,\n",
      " 'geom=connectivity7/8=1,10=1,25=1/1,2,3,16;': 1,\n",
      " 'geom=connectivity8/6=4,10=90,11=11/1;': 1,\n",
      " 'geom=connectivity99//99;': 1,\n",
      " 'geom=connectivityBerny': 1,\n",
      " 'geom=connectivityCharge': 1,\n",
      " 'geom=connectivityCl': 1,\n",
      " 'geom=connectivityGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGrad': 1,\n",
      " 'geom=connectivityInitialization': 1,\n",
      " 'geom=connectivityInput': 1,\n",
      " 'geom=connectivityNumber': 1,\n",
      " 'geom=connectivitySymbolic': 1,\n",
      " 'geom=connectivityTitle': 1,\n",
      " 'geom=connectivityTrust': 1,\n",
      " 'guess=read': 1,\n",
      " 'has': 1,\n",
      " 'hf/3-21g': 3,\n",
      " 'in': 2,\n",
      " 'input': 1,\n",
      " 'internal': 1,\n",
      " 'm=connectivity': 1,\n",
      " 'matrix': 1,\n",
      " 'maximum': 1,\n",
      " 'nos': 1,\n",
      " 'nos!': 1,\n",
      " 'nos-------------------': 1,\n",
      " 'nos--------------------------': 1,\n",
      " 'nos----------------------------': 1,\n",
      " 'nos----------------------------------------------------------------------': 1,\n",
      " 'nos1/6=85,18=20,19=15,26=3,38=1,57=2/1,3;': 1,\n",
      " 'nos1/6=85,18=20,19=15,26=3/3(-5);': 1,\n",
      " 'nos1/6=85,18=20,19=15,26=3/3(2);': 1,\n",
      " 'nos2/9=110,12=2,15=1,17=6,18=5,40=1/2;': 1,\n",
      " 'nos2/9=110,15=1/2;': 1,\n",
      " 'nos3/5=7,11=2,16=1,17=8,25=1,30=1,70=32201,71=1,72=1,74=-5/1,2,3;': 1,\n",
      " 'nos3/5=7,6=1,11=2,16=1,17=8,25=1,30=1,70=32205,71=1,72=1,74=-5,82=7/1,2,3;': 1,\n",
      " 'nos4//1;': 1,\n",
      " 'nos4/5=5,16=3,69=1/1;': 1,\n",
      " 'nos5/5=2,38=5,53=1/2;': 1,\n",
      " 'nos6/7=2,8=2,9=2,10=2,19=2,28=1/1;': 1,\n",
      " 'nos6/7=2,8=2,9=2,10=2,28=1/1;': 1,\n",
      " 'nos7/30=1/1,2,3,16;': 1,\n",
      " 'nos99//99;': 1,\n",
      " 'nos99/9=1/99;': 1,\n",
      " 'nosAdd': 1,\n",
      " 'nosBerny': 1,\n",
      " 'nosC': 1,\n",
      " 'nosCharge': 1,\n",
      " 'nosCl': 1,\n",
      " 'nosGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGrad': 1,\n",
      " 'nosH': 1,\n",
      " 'nosInitialization': 1,\n",
      " 'nosO': 1,\n",
      " 'nosPd': 1,\n",
      " 'nosSymbolic': 1,\n",
      " 'nosTitle': 1,\n",
      " 'nosymm': 2,\n",
      " 'number': 1,\n",
      " 'of': 1,\n",
      " 'opt=(maxcycles=85)': 1,\n",
      " 'opt=(ts,noeigen,readfc,modredundant)': 1,\n",
      " 'opt=maxcycles=85': 1,\n",
      " 'optimization.': 4,\n",
      " 'orientation:': 1,\n",
      " 'pass.': 4,\n",
      " 'pseudo=read': 1,\n",
      " 'read': 1,\n",
      " 'read:': 1,\n",
      " 'run=': 1,\n",
      " 'scrf=(smd,solvent': 1,\n",
      " 'scrf=(smd,solvent!': 1,\n",
      " 'scrf=(smd,solvent\"AllylChlorideClTS-TS.chk\"': 1,\n",
      " 'scrf=(smd,solvent-------------------': 1,\n",
      " 'scrf=(smd,solvent--------------------------': 1,\n",
      " 'scrf=(smd,solvent----------------------------': 1,\n",
      " 'scrf=(smd,solvent----------------------------------------------------------------------': 1,\n",
      " 'scrf=(smd,solvent1/5=1,10=3,11=1,18=120,26=6,29=2,38=1/1,3;': 1,\n",
      " 'scrf=(smd,solvent1/5=1,11=1,18=20,26=6/3(-5);': 1,\n",
      " 'scrf=(smd,solvent1/5=1,11=1,18=20,26=6/3(2);': 1,\n",
      " 'scrf=(smd,solvent2/9=110,12=2,15=1,40=1/2;': 1,\n",
      " 'scrf=(smd,solvent2/9=110,15=1/2;': 1,\n",
      " 'scrf=(smd,solvent3/5=5,11=9,14=-2,25=1,30=1,70=32205,71=1,72=21/1,2,3;': 1,\n",
      " 'scrf=(smd,solvent3/5=5,11=9,14=-4,25=1,30=1,70=32201,71=1,72=21,116=-2/1,2,3;': 1,\n",
      " 'scrf=(smd,solvent4/5=1/1;': 1,\n",
      " 'scrf=(smd,solvent4/5=5,16=3,69=1/1;': 1,\n",
      " 'scrf=(smd,solvent5/5=2,38=5,53=21/2;': 1,\n",
      " 'scrf=(smd,solvent5/5=2,38=6,53=21/2;': 1,\n",
      " 'scrf=(smd,solvent6/7=2,8=2,9=2,10=2,19=2,28=1/1;': 1,\n",
      " 'scrf=(smd,solvent6/7=2,8=2,9=2,10=2,28=1/1;': 1,\n",
      " 'scrf=(smd,solvent7/30=1/1,2,3,16;': 1,\n",
      " 'scrf=(smd,solvent99//99;': 1,\n",
      " 'scrf=(smd,solvent99/9=1/99;': 1,\n",
      " 'scrf=(smd,solvent=dmso)': 3,\n",
      " 'scrf=(smd,solvent=water)': 1,\n",
      " 'scrf=(smd,solventB': 1,\n",
      " 'scrf=(smd,solventBerny': 1,\n",
      " 'scrf=(smd,solventC,0,-0.2475887734,0.429752874,0.0120524767': 1,\n",
      " 'scrf=(smd,solventC,0,-0.290289215,-0.8858065531,0.0674033537': 1,\n",
      " 'scrf=(smd,solventC,0,1.0118266802,1.1819325199,-0.1116872583': 1,\n",
      " 'scrf=(smd,solventCharge': 1,\n",
      " 'scrf=(smd,solventCl,0,1.0820487577,1.3327527288,-2.4496755627': 1,\n",
      " 'scrf=(smd,solventCl,0,1.4317208228,1.5055986407,2.1766003935': 1,\n",
      " 'scrf=(smd,solventForce': 1,\n",
      " 'scrf=(smd,solventGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGradGrad': 1,\n",
      " 'scrf=(smd,solventH,0,-1.1425132255,1.019263475,0.055285699': 1,\n",
      " 'scrf=(smd,solventH,0,-1.2213726388,-1.4123728725,0.1573248761': 1,\n",
      " 'scrf=(smd,solventH,0,0.6007632219,-1.485363254,0.0245781973': 1,\n",
      " 'scrf=(smd,solventH,0,1.0019467677,2.2399101113,-0.1476619449': 1,\n",
      " 'scrf=(smd,solventH,0,1.9398457223,0.6675720299,-0.1607851803': 1,\n",
      " 'scrf=(smd,solventInitialization': 1,\n",
      " 'scrf=(smd,solventRecover': 1,\n",
      " 'scrf=(smd,solventRedundant': 1,\n",
      " 'scrf=(smd,solventStructure': 1,\n",
      " 'scrf=(smd,solventThe': 1,\n",
      " 'scrf=(smd,solventTitle': 1,\n",
      " 'section': 1,\n",
      " 'steps': 1,\n",
      " 'steps=': 1,\n",
      " 'the': 1,\n",
      " 'this': 1,\n",
      " 'virtual': 1,\n",
      " 'ymm': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint as pp\n",
    "# Read in and check the ExtractTest.json file\n",
    "data_path = '/Users/Riley/Documents/Research/User_Input_Module/ExtractTest.json'\n",
    "\n",
    "# Example of importing the data from the json file\n",
    "with open(data_path,\"r\") as file_obj :\n",
    "    [link0_mostFreq,route_mostFreq] = json.load(file_obj)\n",
    "\n",
    "pp.pprint(link0_mostFreq)\n",
    "pp.pprint(route_mostFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'--'\n"
     ]
    }
   ],
   "source": [
    "multiplier = len(line)\n",
    "result = b\"-\"*multiplier\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Error Block\n",
    "\n",
    "def extract_data(file_obj: file_wrapper) -> tuple[list[str]] :\n",
    "    # Initialize local var\n",
    "    link0 = bytearray()\n",
    "    route_cmds = bytearray()\n",
    "    extracted = False\n",
    "\n",
    "    # Move the cursor to the beginning of the file\n",
    "    file_obj.seek(0)\n",
    "\n",
    "    # Read first line\n",
    "    line = file_obj.readline()\n",
    "    while line:\n",
    "        # if the line starts with a %, it is a link0 command\n",
    "        if b\"%\" in line[:3] :\n",
    "                line = line.split()\n",
    "                [link0.extend(b\" \" + elem) for elem in line if b\"%\" in elem and elem != b\"\"]\n",
    "        # if the line starts with a #, it's the route section line\n",
    "        elif b\"#\" in line[:3] :\n",
    "            end_line = b\"-\"*len(line)\n",
    "            line = line.split()\n",
    "            [route_cmds.extend(b\" \" + elem) for elem in line if b\"#\" not in elem and elem != b\"\"]\n",
    "            # Grab the last keyword in case line spills over\n",
    "            end_keyword = line[len(line) - 1]\n",
    "            # grab next line if the contents spill over\n",
    "            line = file_obj.readline()\n",
    "            while end_line not in line :\n",
    "                line = line.split()\n",
    "                # Chances are if the line spills it wrecks a keyword. This takes the last keyword\n",
    "                # and combines it with the first of the next line\n",
    "                if len(line) > 0 :\n",
    "                    start_keyword = line[0]\n",
    "                    # Add the joined keyword\n",
    "                    route_cmds.extend(b\" \"+end_keyword+start_keyword)\n",
    "                # Extend bytearray by the additional keywords\n",
    "                [route_cmds.extend(b\" \" + elem) for elem in line if elem != b\"\"]\n",
    "                # Read the next line\n",
    "                line = file_obj.readline()\n",
    "            extracted = True\n",
    "        \n",
    "        # Once the route section commands are collected, stop iterating over the lines in the file.\n",
    "        if extracted is True:\n",
    "            break\n",
    "        # Iterate over the next line until the route section is collected\n",
    "        line = file_obj.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "# freq hf/3-21g scrf=(smd,solvent=dmso) geom=connectivity\n",
      " ----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "line1 = \" ---------------------------------------------------------\\n\"\n",
    "line2 = \" # freq hf/3-21g scrf=(smd,solvent=dmso) geom=connectivity\\n\"\n",
    "line3 = \" ---------------------------------------------------------\\n\"\n",
    "\n",
    "print(len(line2))\n",
    "print(line2.strip())\n",
    "print(\" \"+\"-\"*(len(line2)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "219f28c729eda709583e1ab80762c396fbb24857f282d49252dc64048c611cb8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('MOD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
