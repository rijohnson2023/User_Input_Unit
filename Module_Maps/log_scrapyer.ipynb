{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rought plan\n",
    "\n",
    "1. Set up path to place files\n",
    "2. get the source_directory to search for the files\n",
    "3. os.walk() to find the files\n",
    "4. open the file\n",
    "   1. move pointer to the end of file if not using \"a+\" mode\n",
    "   2. normal termination line\n",
    "      1. if no normal termination line break and move on to next file\n",
    "   3. move pointer to the top of the file\n",
    "   4. iterate using readline\n",
    "      1. startswith(\"%\"), grab line\n",
    "      2. startswith(\"#\") grab line and all lines after until reach \"------\" line\n",
    "   5. end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate/setup directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Riley/Documents/Research/User_Input_Module/LogFile\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def set_data_path() -> str:\n",
    "    outfile_name = input(\"Name the file to store the data:\\n(Do not include the extension)\\n\")\n",
    "\n",
    "    # Locate current working directory as destination for report\n",
    "    data_path = os.path.join(os.getcwd(),outfile_name)\n",
    "\n",
    "    while True :\n",
    "        # Two answers: acceptable: 1. path, 2. \"\", all else are bad\"\n",
    "        answer = str(input(\"The data recorded will be at path:\\n%10s\\nHit enter to proceed, or type new path without '/LogData.csv':\\n  \" % data_path))\n",
    "        if answer == \"\" :\n",
    "            break\n",
    "        elif os.path.isdir(answer) :\n",
    "            data_path = os.path.join(answer,outfile_name)\n",
    "            break\n",
    "\n",
    "    return data_path\n",
    "\n",
    "def test() :\n",
    "    \"\"\"\n",
    "    Simple data file string is:\n",
    "            LogFile\n",
    "\n",
    "    Copy and past path:\n",
    "            /Users/Riley/Documents/Research/User_Input_Module/\n",
    "    \"\"\"\n",
    "    data_path = set_data_path()\n",
    "    print(data_path)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 log files were found in the directory branch:\n",
      "/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/\n",
      "['/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChlorideClTS.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/NotNormalTerm.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/EmptyFile.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/Pd2p-ene-CO-transcis-P-fromciscis.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/Cl.log',\n",
      " '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChloride.log']\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "def find_files_in_dir() -> list[str] :\n",
    "    # Get valid source directory from user\n",
    "    source_dir = input(\"Please input the directory path to search:\\n\")\n",
    "    while not os.path.isdir(source_dir) :\n",
    "        source_dir = input(\"Invalid path, enter a new directory path to search:\\n\")\n",
    "\n",
    "    # Create a list of all the log files in the directory\n",
    "    listoffiles = list()\n",
    "    for (dirpath, dir_names, filenames) in os.walk(source_dir):\n",
    "        listoffiles += [os.path.join(dirpath,file) for file in filenames if file.split(\".\")[len(file.split(\".\"))-1] == \"log\"]\n",
    "\n",
    "    print(\"%d log files were found in the directory branch:\\n%s\" % (len(listoffiles), source_dir))\n",
    "    return listoffiles\n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    Use example files in the directory at the path:\n",
    "            /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/\n",
    "    \"\"\"\n",
    "    file_list = find_files_in_dir()\n",
    "    pp.pprint(file_list)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling the file challenge\n",
    "open the file\n",
    "   1. move pointer to the end of file if not using \"a+\" mode\n",
    "   2. normal termination line\n",
    "      1. if no normal termination line break and move on to next file\n",
    "   3. move pointer to the top of the file\n",
    "   4. iterate using readline\n",
    "      1. startswith(\"%\"), grab line\n",
    "      2. startswith(\"#\") grab line and all lines after until reach \"------\" line\n",
    "   5. end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File, AllylChloride.log, terminated normally.\n",
      "File, AllylChlorideClTS.log, terminated normally.\n",
      "Normal termination not detected in NotNormalTerm.log.\n",
      "File, EmptyFile.log, is empty.\n",
      "    File:\n",
      "     /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChloride.log\n",
      "     Normal termination: True\n",
      "    File:\n",
      "     /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChlorideClTS.log\n",
      "     Normal termination: True\n",
      "    File:\n",
      "     /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/NotNormalTerm.log\n",
      "     Normal termination: False\n",
      "    File:\n",
      "     /Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/EmptyFile.log\n",
      "     Normal termination: False\n"
     ]
    }
   ],
   "source": [
    "from asyncore import file_wrapper\n",
    "\n",
    "def check_log_file(file_path: str, file_obj: file_wrapper) -> bool:\n",
    "    \"\"\"\n",
    "    Check log file searches the file object for the line\n",
    "    \"Normal termination of Gaussian 16\"\n",
    "\n",
    "    This is usually a substring of the last line in the log file, if it terminates correctly.\n",
    "    Sometimes with multistep calculations, there will be a \"Normal termination of Gaussian 16\"\n",
    "    line for every calculation step, or some may contain a \"Error termination of Gaussian 16.\"\n",
    "\n",
    "    We only want to record the keywords from the files that have terminated normally.\n",
    "    Those keywords are deemed as valid by the Gaussian 16 software.\n",
    "    Therefore, the log file must pass this check if we are going to count its keywords.\n",
    "\n",
    "    This function iterates over the bytes/characters of the file in reverse order until it finds the line\n",
    "    \"Normal termination of Gaussian 16.\" Keep in mind that if the file contains multi-step calculations,\n",
    "    and one of those calculations finished successfully, then the keywords will be counted.\n",
    "    \"\"\"\n",
    "    check = True\n",
    "    empty = False\n",
    "\n",
    "    file_name = (file_path.split(\"/\"))[len(file_path.split(\"/\"))-1]\n",
    "\n",
    "    # Check if size of file is 0\n",
    "    if os.stat(file_path).st_size == 0 :\n",
    "        empty = True\n",
    "        check = False\n",
    "\n",
    "    if empty != True :\n",
    "        # Move the cursor to the end of the file\n",
    "        file_obj.seek(0, os.SEEK_END)\n",
    "\n",
    "        # Get the current position of the pointer\n",
    "        pointer_location = file_obj.tell()\n",
    "        \n",
    "        # Create a buffer to keep the last read line\n",
    "        buffer = bytearray()\n",
    "\n",
    "        #Loop in reverse order until \"Normal termination\" line is found\n",
    "        while pointer_location >= 0 :\n",
    "            # Move the file pointer to the location pointed by the pointer\n",
    "            file_obj.seek(pointer_location)\n",
    "\n",
    "            pointer_location -= 1 # Shift pointer location back by 1\n",
    "            \n",
    "            new_byte = file_obj.read(1) # Read that byte/character\n",
    "\n",
    "            if new_byte == b'\\n' : # If the byte is a newline character, then the end of a line has been reached\n",
    "                line = buffer.decode()[::-1] #Fetch the line from buffer\n",
    "                if 'Normal termination of Gaussian 16' in line :\n",
    "                    print(\"File, %s, terminated normally.\" % file_name)\n",
    "                    break\n",
    "                # Reinitialize the byte array to save next line\n",
    "                buffer = bytearray()\n",
    "            else:\n",
    "                buffer.extend(new_byte)\n",
    "\n",
    "        # As file is read completely, if the line has not been detected then the file did not terminate normally.\n",
    "        if pointer_location <= 0:\n",
    "            print(\"Normal termination not detected in %s.\" %file_name)\n",
    "            check = False\n",
    "    else:\n",
    "        print(\"File, %s, is empty.\" % file_name)\n",
    "\n",
    "    return check\n",
    "\n",
    "def test():\n",
    "\n",
    "    # file_path1 is a perfectly completed calculation file\n",
    "    file_path1 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChloride.log'\n",
    "    file_path2 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChlorideClTS.log'\n",
    "\n",
    "    # file_path2 is a multi-step calculation log file. Both calculations terminated with error\n",
    "    file_path3 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/NotNormalTerm.log'\n",
    "    # file_path3 is an empty file with a log extension\n",
    "    file_path4 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/EmptyFile.log'\n",
    "    file_list = [file_path1,file_path2,file_path3, file_path4]\n",
    "    \n",
    "    checks = list()\n",
    "    for file_path in file_list :\n",
    "        with open(file_path,\"rb\") as file_obj :\n",
    "            checks.append(check_log_file(file_path,file_obj))\n",
    "    \n",
    "    [print(\"    File:\\n     %s\\n     Normal termination: %s\" %(file,checks[index])) for index, file in enumerate(file_list)]\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the data from the log file\n",
    "\n",
    "> The file has already been read as a binary file\n",
    "> \n",
    ">   - This was to check the last lines to see if it contained \"Normal termination of Gaussian 16\"\n",
    "> \n",
    ">   - There really isn't a need to read binary, unless that is required for reading the last line.\n",
    "> \n",
    "> For extracting the keywords, intuitively, it could also be read character by character. The difficulty would be making sure the characters don't get combined all together\n",
    "> \n",
    "> It seems easier to read by line. \n",
    "> \n",
    ">   - The challenge of reading line by line is if the Route section spills over into two lines, then its possible one of the keywords will get messed up. \n",
    "> \n",
    ">   - This multiplies one keyword messed up for every line spilled over. So for every line spilled over there are two bad inputs. \n",
    "> \n",
    ">   - Ideally, there won't be that many, so these will be relatively low scoring keywords when counting them as popular data.\n",
    "> \n",
    "> The next task is to compile all of the keywords into a dictionary that counts them. Then to sort the dictionary by the values, and write it into an outfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File, AllylChloride.log, terminated normally.\n",
      "['%chk=AllylChloride.chk', '%nprocs=60', '%mem=60GB']\n",
      "['opt=(maxcycles=85)', 'freq=noraman', 'hf/3-21g', 'scrf=(smd,solvent=dmso)', 'geo', 'm=connectivity']\n",
      "\n",
      "File, AllylChlorideClTS.log, terminated normally.\n",
      "['%oldchk=AllylChlorideClTS.chk', '%chk=AllylChlorideClTS-TS.chk']\n",
      "['opt=(ts,noeigen,readfc,modredundant)', 'freq', 'hf/3-21g', 'scrf=(smd,solvent', '=dmso)', 'nosymm', 'geom=checkpoint', 'guess=read']\n",
      "\n",
      "Normal termination not detected in NotNormalTerm.log.\n",
      "File, EmptyFile.log, is empty.\n"
     ]
    }
   ],
   "source": [
    "def extract_data(file_obj: file_wrapper) -> tuple[list[str]]:\n",
    "    # Initialize local var\n",
    "    link0 = bytearray()\n",
    "    route_cmds = bytearray()\n",
    "\n",
    "    # Move the cursor to the beginning of the file\n",
    "    file_obj.seek(0)\n",
    "\n",
    "    # Read first line\n",
    "    line = file_obj.readline()\n",
    "    while line:\n",
    "        # if the line starts with a %, it is a link0 command\n",
    "        if b\"%\" in line[:3] :\n",
    "                #print(\"Found link0 input\\n%s\" % line)\n",
    "                line = line.split()\n",
    "                [link0.extend(b\" \" + elem) for elem in line if b\"%\" in elem and elem != b\"\"]\n",
    "        # if the line starts with a #, it's the route section line\n",
    "        elif b\"#\" in line[:3] :\n",
    "            #print(\"Found Route Line\\n%s\" % line)\n",
    "            line = line.split()\n",
    "            [route_cmds.extend(b\" \" + elem) for elem in line if b\"#\" not in elem and elem != b\"\"]\n",
    "            # grab next line if the contents spill over\n",
    "            line = file_obj.readline()\n",
    "            while line :\n",
    "                if b'----------------------------------------------------------------------' in line :\n",
    "                    break\n",
    "                line = line.split()\n",
    "                [route_cmds.extend(b\" \" + elem) for elem in line if elem != b\"\"]\n",
    "                line = file_obj.readline()\n",
    "            break\n",
    "        line = file_obj.readline()\n",
    "\n",
    "    return link0.decode(\"ascii\").split(), route_cmds.decode(\"ascii\").split()\n",
    "\n",
    "\n",
    "def test():\n",
    "    # file_path1 is a perfectly completed calculation file\n",
    "    file_path1 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChloride.log'\n",
    "    file_path2 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/AllylChlorideClTS.log'\n",
    "\n",
    "    # file_path2 is a multi-step calculation log file. Both calculations terminated with error\n",
    "    file_path3 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/NotNormalTerm.log'\n",
    "    # file_path3 is an empty file with a log extension\n",
    "    file_path4 = '/Users/Riley/Documents/Research/User_Input_Module/Gaussian_Outputs_Keywords/EmptyFile.log'\n",
    "    file_list = [file_path1,file_path2,file_path3, file_path4]\n",
    "\n",
    "    for file_path in file_list :\n",
    "        with open(file_path,\"rb\") as infile :\n",
    "            check = check_log_file(file_path=file_path,file_obj=infile)\n",
    "            if check : \n",
    "                (link0, route_cmds) = extract_data(file_obj=infile)\n",
    "                print(link0)\n",
    "                print(route_cmds)\n",
    "                print()\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'%chk=AllylChloride.chk': 1,\n",
      " '%chk=AllylChlorideClTS-TS.chk': 1,\n",
      " '%mem=60GB': 1,\n",
      " '%nprocs=60': 1,\n",
      " '%oldchk=AllylChlorideClTS.chk': 1}\n",
      "{}\n",
      "{'freq': 1,\n",
      " 'geom=checkpoint': 1,\n",
      " 'guess=read': 1,\n",
      " 'hf/3-21g': 1,\n",
      " 'nosymm': 1,\n",
      " 'opt=(ts,noeigen,readfc,modredundant)': 1,\n",
      " 'scrf=(smd,solvent=dmso)': 1}\n"
     ]
    }
   ],
   "source": [
    "def update_mostFreq_data(mostFreq_dict:dict[str:int], keywords:list[str]) -> None:\n",
    "    \"\"\" \n",
    "    This function updates the mostFreq data used to track the most popular G16 keywords:\n",
    "    Update the count if the keyword is in the dictionary.\n",
    "    If the keyword is not in the dictionary, its added with a default count of 1.\n",
    "    \"\"\"\n",
    "    [mostFreq_dict.update({elem:mostFreq_dict[elem]+1}) for elem in keywords if elem in mostFreq_dict.keys()]\n",
    "    [mostFreq_dict.setdefault(elem,1) for elem in keywords if elem not in mostFreq_dict.keys()]\n",
    "\n",
    "def test():\n",
    "    # Data output by the extract data function\n",
    "    link0 = ['%oldchk=AllylChlorideClTS.chk', '%chk=AllylChlorideClTS-TS.chk', '%nprocs=60', '%mem=60GB', '%chk=AllylChloride.chk']\n",
    "    route_cmds = ['opt=(ts,noeigen,readfc,modredundant)', 'freq', 'hf/3-21g', 'scrf=(smd,solvent=dmso)', 'nosymm', 'geom=checkpoint', 'guess=read']\n",
    "\n",
    "    # Initializing variables for the data. These need to be either global variables or class variables, \n",
    "    # so all the files update the same dictionary\n",
    "    link0_mostFreq = dict()\n",
    "    route_mostFreq = dict()\n",
    "\n",
    "    # Example link0 keyword update\n",
    "    pp.pprint(link0_mostFreq)\n",
    "    update_mostFreq_data(link0_mostFreq,link0)\n",
    "    pp.pprint(link0_mostFreq)\n",
    "    \n",
    "    # Example Route Section Keyword Update\n",
    "    pp.pprint(route_mostFreq)\n",
    "    update_mostFreq_data(route_mostFreq,route_cmds)\n",
    "    pp.pprint(route_mostFreq)\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "219f28c729eda709583e1ab80762c396fbb24857f282d49252dc64048c611cb8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('MOD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
